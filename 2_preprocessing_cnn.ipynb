{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1.전처리\n",
        "- feature: 각 이미지에 대해 HSV, LAB, RGB 평균/표준편차 통계/ 피부 채도 비율 (로우 채도 피부인지)/ 대표 RGB dominant 색상 2개\n",
        "- 이미지 500 -> 2000로 늘림"
      ],
      "metadata": {
        "id": "v4ETXlc4xtTw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1gnd9_fIxAL2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 기본 설정\n",
        "dataset_path = '/content/drive/MyDrive/dataset_for_capstone'\n",
        "seasons = ['spring_cropped', 'summer_cropped', 'autumn_cropped', 'winter_cropped']\n",
        "output_csv = '/content/drive/MyDrive/personal_color_features.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HSV 기반 피부 마스크 함수\n",
        "def skin_mask_hsv(img):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    lower = np.array([0, 20, 70], dtype=np.uint8)\n",
        "    upper = np.array([50, 255, 255], dtype=np.uint8)\n",
        "    mask = cv2.inRange(hsv, lower, upper)\n",
        "    return mask\n",
        "\n",
        "# Dominant color 추출 함수\n",
        "def extract_dominant_color(img, mask, k=2):\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "    pixels = masked_img[mask > 0]\n",
        "    if len(pixels) == 0:\n",
        "        return [0, 0, 0] * k\n",
        "    kmeans = KMeans(n_clusters=k, n_init='auto')\n",
        "    kmeans.fit(pixels)\n",
        "    centers = kmeans.cluster_centers_.astype(int)\n",
        "    return centers.flatten().tolist()\n",
        "\n",
        "# feature 추출\n",
        "def extract_features(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    mask = skin_mask_hsv(img)\n",
        "\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    rgb = img\n",
        "\n",
        "    skin_indices = np.where(mask > 0)\n",
        "\n",
        "    if len(skin_indices[0]) < 50:\n",
        "        return None\n",
        "\n",
        "    def channel_stats(channel):\n",
        "        values = channel[skin_indices]\n",
        "        return np.mean(values), np.std(values)\n",
        "\n",
        "    # HSV\n",
        "    mean_H, std_H = channel_stats(hsv[:, :, 0])\n",
        "    mean_S, std_S = channel_stats(hsv[:, :, 1])\n",
        "    mean_V, std_V = channel_stats(hsv[:, :, 2])\n",
        "    # LAB\n",
        "    mean_L, std_L = channel_stats(lab[:, :, 0])\n",
        "    mean_a, std_a = channel_stats(lab[:, :, 1])\n",
        "    mean_b, std_b = channel_stats(lab[:, :, 2])\n",
        "    # RGB\n",
        "    mean_R, std_R = channel_stats(rgb[:, :, 2])\n",
        "    mean_G, std_G = channel_stats(rgb[:, :, 1])\n",
        "    mean_B, std_B = channel_stats(rgb[:, :, 0])\n",
        "\n",
        "    S_vals = hsv[:, :, 1][skin_indices]\n",
        "    low_s_ratio = np.sum(S_vals < 40) / len(S_vals)\n",
        "\n",
        "    dom_colors = extract_dominant_color(img, mask, k=2)\n",
        "\n",
        "    return [\n",
        "        mean_H, std_H, mean_S, std_S, mean_V, std_V,\n",
        "        mean_L, std_L, mean_a, std_a, mean_b, std_b,\n",
        "        mean_R, std_R, mean_G, std_G, mean_B, std_B,\n",
        "        low_s_ratio, *dom_colors\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "CBaBsXR4xVdp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 반복\n",
        "results = []\n",
        "for season in seasons:\n",
        "    folder = os.path.join(dataset_path, f\"{season}_cropped\")\n",
        "    for fname in tqdm(os.listdir(folder), desc=season):\n",
        "        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "        fpath = os.path.join(folder, fname)\n",
        "        features = extract_features(fpath)\n",
        "        if features:\n",
        "            results.append([fname, season] + features)"
      ],
      "metadata": {
        "id": "05-hCvMLxrGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['image_name', 'season',\n",
        "           'mean_H', 'std_H', 'mean_S', 'std_S', 'mean_V', 'std_V',\n",
        "           'mean_L', 'std_L', 'mean_a', 'std_a', 'mean_b', 'std_b',\n",
        "           'mean_R', 'std_R', 'mean_G', 'std_G', 'mean_B', 'std_B',\n",
        "           'low_s_ratio',\n",
        "           'dom1_R', 'dom1_G', 'dom1_B', 'dom2_R', 'dom2_G', 'dom2_B']\n",
        "\n",
        "# CSV 저장\n",
        "df = pd.DataFrame(results, columns=columns)\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"✅ Feature CSV saved to: {output_csv}\")"
      ],
      "metadata": {
        "id": "DnVexFTufepE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. CNN 모델 개발"
      ],
      "metadata": {
        "id": "7m_lCYSVfke4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XyhB_h5vfp2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_path = '/content/drive/MyDrive/personal_color_result.csv'\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "X = data[['H', 'S', 'V']].values  # HSV 입력\n",
        "y = data[['spring', 'summer', 'autumn', 'winter']].values  # 원-핫 인코딩된 계절 라벨\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# CNN 모델에 맞게 차원 확장\n",
        "X_train = X_train.reshape(-1, 3, 1)\n",
        "X_val = X_val.reshape(-1, 3, 1)"
      ],
      "metadata": {
        "id": "kv80QrzeyiSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CNN 모델 구성\n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(3, 1)),\n",
        "    Dropout(0.3),\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(4, activation='softmax')  # 출력 4개 (계절)\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FYodOlffylrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "#모델 학습\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "gHSyTwRjysUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('CNN Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5pDLiWzIyv1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv('/content/drive/MyDrive/personal_color_result.csv')\n",
        "\n",
        "# 입력 X, 라벨 y (단일 라벨 인코딩)\n",
        "X = data[['H', 'S', 'V']].values\n",
        "y_labels = data[['spring', 'summer', 'autumn', 'winter']].idxmax(axis=1)\n",
        "label_map = {'spring':0, 'summer':1, 'autumn':2, 'winter':3}\n",
        "y = y_labels.map(label_map).values\n",
        "y = to_categorical(y, 4)\n",
        "\n",
        "# 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 간단한 모델 함수\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(3,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 교차검증\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "acc_per_fold = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X_scaled, y_labels):\n",
        "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=30, batch_size=16, verbose=0)\n",
        "    scores = model.evaluate(X_val, y_val, verbose=0)\n",
        "    acc_per_fold.append(scores[1])\n",
        "    print(f'Validation Accuracy: {scores[1]:.4f}')\n",
        "\n",
        "print(f'Average Validation Accuracy: {np.mean(acc_per_fold):.4f}')"
      ],
      "metadata": {
        "id": "V7TeRDZRyzbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}